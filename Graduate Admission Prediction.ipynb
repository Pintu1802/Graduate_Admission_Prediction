{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01028a5d",
   "metadata": {},
   "source": [
    "# Graduate Admission Prediction Using Keras Regression Deep Learning ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fadcd",
   "metadata": {},
   "source": [
    "Graduate Admission Prediction is a task in data science and machine learning that involves predicting the likelihood of a student being admitted to a graduate program based on various factors such as their academic performance, standardized test scores, letters of recommendation, statement of purpose, and other relevant attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c6761",
   "metadata": {},
   "source": [
    "                           SUBNITTED BY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4edf87",
   "metadata": {},
   "source": [
    "                    PINTU KUMAR SAH SID- 100223 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962de9bf",
   "metadata": {},
   "source": [
    "                     UNDER SUPERVISION OF \n",
    "                     MR.VIVEK PANDEY SIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8176aa39",
   "metadata": {},
   "source": [
    "# Now import the required libraries ,read the csv file than after show the top 5 rows and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aceef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required library \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3556507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\All Subject(6)\\\\Samatrix\\\\archive (8)\\\\Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbe9497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8327c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it shows the total number of rows and no. of columns of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233e5cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>168</td>\n",
       "      <td>313</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>301</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "167         168        313          102                  3  2.0   3.0  8.27   \n",
       "77           78        301           99                  2  3.0   2.0  8.22   \n",
       "37           38        300          105                  1  1.0   2.0  7.80   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "167         0              0.64  \n",
       "77          0              0.64  \n",
       "37          0              0.58  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51068811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.807500</td>\n",
       "      <td>107.410000</td>\n",
       "      <td>3.087500</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.452500</td>\n",
       "      <td>8.598925</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.724350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.473646</td>\n",
       "      <td>6.069514</td>\n",
       "      <td>1.143728</td>\n",
       "      <td>1.006869</td>\n",
       "      <td>0.898478</td>\n",
       "      <td>0.596317</td>\n",
       "      <td>0.498362</td>\n",
       "      <td>0.142609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.062500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GRE Score  TOEFL Score  University Rating         SOP        LOR   \\\n",
       "count  400.000000   400.000000         400.000000  400.000000  400.000000   \n",
       "mean   316.807500   107.410000           3.087500    3.400000    3.452500   \n",
       "std     11.473646     6.069514           1.143728    1.006869    0.898478   \n",
       "min    290.000000    92.000000           1.000000    1.000000    1.000000   \n",
       "25%    308.000000   103.000000           2.000000    2.500000    3.000000   \n",
       "50%    317.000000   107.000000           3.000000    3.500000    3.500000   \n",
       "75%    325.000000   112.000000           4.000000    4.000000    4.000000   \n",
       "max    340.000000   120.000000           5.000000    5.000000    5.000000   \n",
       "\n",
       "             CGPA    Research  Chance of Admit   \n",
       "count  400.000000  400.000000        400.000000  \n",
       "mean     8.598925    0.547500          0.724350  \n",
       "std      0.596317    0.498362          0.142609  \n",
       "min      6.800000    0.000000          0.340000  \n",
       "25%      8.170000    0.000000          0.640000  \n",
       "50%      8.610000    1.000000          0.730000  \n",
       "75%      9.062500    1.000000          0.830000  \n",
       "max      9.920000    1.000000          0.970000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe() method returns description of the data in the DataFrame (i.e. count, mean, std, etc)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3035113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          400 non-null    int64  \n",
      " 1   TOEFL Score        400 non-null    int64  \n",
      " 2   University Rating  400 non-null    int64  \n",
      " 3   SOP                400 non-null    float64\n",
      " 4   LOR                400 non-null    float64\n",
      " 5   CGPA               400 non-null    float64\n",
      " 6   Research           400 non-null    int64  \n",
      " 7   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 25.1 KB\n"
     ]
    }
   ],
   "source": [
    "# To show the index, columns, data-types of each columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce19f296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check for missing values in each column.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ab3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'Serial No.'\n",
    "df.drop(columns=['Serial No.'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358e0a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e3ac1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the selected data into a NumPy array.\n",
    "X=df.iloc[:,0:-1].values\n",
    "y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b5a4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[337.  , 118.  ,   4.  , ...,   4.5 ,   9.65,   1.  ],\n",
       "       [324.  , 107.  ,   4.  , ...,   4.5 ,   8.87,   1.  ],\n",
       "       [316.  , 104.  ,   3.  , ...,   3.5 ,   8.  ,   1.  ],\n",
       "       ...,\n",
       "       [330.  , 116.  ,   4.  , ...,   4.5 ,   9.45,   1.  ],\n",
       "       [312.  , 103.  ,   3.  , ...,   4.  ,   8.78,   0.  ],\n",
       "       [333.  , 117.  ,   4.  , ...,   4.  ,   9.66,   1.  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bf9d612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92, 0.76, 0.72, 0.8 , 0.65, 0.9 , 0.75, 0.68, 0.5 , 0.45, 0.52,\n",
       "       0.84, 0.78, 0.62, 0.61, 0.54, 0.66, 0.65, 0.63, 0.62, 0.64, 0.7 ,\n",
       "       0.94, 0.95, 0.97, 0.94, 0.76, 0.44, 0.46, 0.54, 0.65, 0.74, 0.91,\n",
       "       0.9 , 0.94, 0.88, 0.64, 0.58, 0.52, 0.48, 0.46, 0.49, 0.53, 0.87,\n",
       "       0.91, 0.88, 0.86, 0.89, 0.82, 0.78, 0.76, 0.56, 0.78, 0.72, 0.7 ,\n",
       "       0.64, 0.64, 0.46, 0.36, 0.42, 0.48, 0.47, 0.54, 0.56, 0.52, 0.55,\n",
       "       0.61, 0.57, 0.68, 0.78, 0.94, 0.96, 0.93, 0.84, 0.74, 0.72, 0.74,\n",
       "       0.64, 0.44, 0.46, 0.5 , 0.96, 0.92, 0.92, 0.94, 0.76, 0.72, 0.66,\n",
       "       0.64, 0.74, 0.64, 0.38, 0.34, 0.44, 0.36, 0.42, 0.48, 0.86, 0.9 ,\n",
       "       0.79, 0.71, 0.64, 0.62, 0.57, 0.74, 0.69, 0.87, 0.91, 0.93, 0.68,\n",
       "       0.61, 0.69, 0.62, 0.72, 0.59, 0.66, 0.56, 0.45, 0.47, 0.71, 0.94,\n",
       "       0.94, 0.57, 0.61, 0.57, 0.64, 0.85, 0.78, 0.84, 0.92, 0.96, 0.77,\n",
       "       0.71, 0.79, 0.89, 0.82, 0.76, 0.71, 0.8 , 0.78, 0.84, 0.9 , 0.92,\n",
       "       0.97, 0.8 , 0.81, 0.75, 0.83, 0.96, 0.79, 0.93, 0.94, 0.86, 0.79,\n",
       "       0.8 , 0.77, 0.7 , 0.65, 0.61, 0.52, 0.57, 0.53, 0.67, 0.68, 0.81,\n",
       "       0.78, 0.65, 0.64, 0.64, 0.65, 0.68, 0.89, 0.86, 0.89, 0.87, 0.85,\n",
       "       0.9 , 0.82, 0.72, 0.73, 0.71, 0.71, 0.68, 0.75, 0.72, 0.89, 0.84,\n",
       "       0.93, 0.93, 0.88, 0.9 , 0.87, 0.86, 0.94, 0.77, 0.78, 0.73, 0.73,\n",
       "       0.7 , 0.72, 0.73, 0.72, 0.97, 0.97, 0.69, 0.57, 0.63, 0.66, 0.64,\n",
       "       0.68, 0.79, 0.82, 0.95, 0.96, 0.94, 0.93, 0.91, 0.85, 0.84, 0.74,\n",
       "       0.76, 0.75, 0.76, 0.71, 0.67, 0.61, 0.63, 0.64, 0.71, 0.82, 0.73,\n",
       "       0.74, 0.69, 0.64, 0.91, 0.88, 0.85, 0.86, 0.7 , 0.59, 0.6 , 0.65,\n",
       "       0.7 , 0.76, 0.63, 0.81, 0.72, 0.71, 0.8 , 0.77, 0.74, 0.7 , 0.71,\n",
       "       0.93, 0.85, 0.79, 0.76, 0.78, 0.77, 0.9 , 0.87, 0.71, 0.7 , 0.7 ,\n",
       "       0.75, 0.71, 0.72, 0.73, 0.83, 0.77, 0.72, 0.54, 0.49, 0.52, 0.58,\n",
       "       0.78, 0.89, 0.7 , 0.66, 0.67, 0.68, 0.8 , 0.81, 0.8 , 0.94, 0.93,\n",
       "       0.92, 0.89, 0.82, 0.79, 0.58, 0.56, 0.56, 0.64, 0.61, 0.68, 0.76,\n",
       "       0.86, 0.9 , 0.71, 0.62, 0.66, 0.65, 0.73, 0.62, 0.74, 0.79, 0.8 ,\n",
       "       0.69, 0.7 , 0.76, 0.84, 0.78, 0.67, 0.66, 0.65, 0.54, 0.58, 0.79,\n",
       "       0.8 , 0.75, 0.73, 0.72, 0.62, 0.67, 0.81, 0.63, 0.69, 0.8 , 0.43,\n",
       "       0.8 , 0.73, 0.75, 0.71, 0.73, 0.83, 0.72, 0.94, 0.81, 0.81, 0.75,\n",
       "       0.79, 0.58, 0.59, 0.47, 0.49, 0.47, 0.42, 0.57, 0.62, 0.74, 0.73,\n",
       "       0.64, 0.63, 0.59, 0.73, 0.79, 0.68, 0.7 , 0.81, 0.85, 0.93, 0.91,\n",
       "       0.69, 0.77, 0.86, 0.74, 0.57, 0.51, 0.67, 0.72, 0.89, 0.95, 0.79,\n",
       "       0.39, 0.38, 0.34, 0.47, 0.56, 0.71, 0.78, 0.73, 0.82, 0.62, 0.96,\n",
       "       0.96, 0.46, 0.53, 0.49, 0.76, 0.64, 0.71, 0.84, 0.77, 0.89, 0.82,\n",
       "       0.84, 0.91, 0.67, 0.95])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c421fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler      # Import the StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83cc8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)               # X using the StandardScaler object scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc75ddc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76210664,  1.74697064,  0.79882862, ...,  1.16732114,\n",
       "         1.76481828,  0.90911166],\n",
       "       [ 0.62765641, -0.06763531,  0.79882862, ...,  1.16732114,\n",
       "         0.45515126,  0.90911166],\n",
       "       [-0.07046681, -0.56252785, -0.07660001, ...,  0.05293342,\n",
       "        -1.00563118,  0.90911166],\n",
       "       ...,\n",
       "       [ 1.15124883,  1.41704229,  0.79882862, ...,  1.16732114,\n",
       "         1.42900622,  0.90911166],\n",
       "       [-0.41952842, -0.72749202, -0.07660001, ...,  0.61012728,\n",
       "         0.30403584, -1.09997489],\n",
       "       [ 1.41304503,  1.58200646,  0.79882862, ...,  0.61012728,\n",
       "         1.78160888,  0.90911166]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4166863",
   "metadata": {},
   "source": [
    "# used to split the data into training and testing sets for both features (X) and target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa799f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "642af8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecc59d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f711917c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71492181, 0.5922214 , 0.79882862, 0.59665321, 1.16732114,\n",
       "       0.85812573, 0.90911166])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea0d016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c6f50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60d1243d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063778e8",
   "metadata": {},
   "source": [
    "# using the ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f027df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(7,activation='relu',input_dim=X_train.shape[1]))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed38c737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64\n",
      "Trainable params: 64\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bce0c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e817933",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(7,))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01ecd2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca388a0",
   "metadata": {},
   "source": [
    "# used to train a neural network model using the specified training data and training configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "253c557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 903us/step - loss: 1.0072\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.8257\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.6900\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.5839\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.5026\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.4390\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.3855\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3413\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.3031\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2703\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2412\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2154\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1924\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1717\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1533\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1366\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1217\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1084\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0961\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0854\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0757\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.0672\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0594\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0526\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0466\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0413\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0366\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0325\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0289\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0257\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0230\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0207\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0185\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0167\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0151\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0138\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0126\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0116\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0107\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0087\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0082\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0077\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0074\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0070\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0067\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0065\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0063\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0060\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0059\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0057\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.0056\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0054\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0053\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0052\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0048\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0048\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0047\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0047\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0046\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0046\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0046\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0045\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0045\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0045\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0044\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0044\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0044\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0044\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0044\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0044\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0043\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0042\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0042\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0042\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0042\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0042\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.0042\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20574a0c100>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aa4ad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c29689f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.808706  , 0.84565983, 0.50642444, 0.69133529, 0.45036351])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = model.predict(X_test)\n",
    "yp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab296135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the binary predictions.\n",
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "736c90ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3dbedb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84, 0.87, 0.45, 0.76, 0.57, 0.81, 0.78, 0.69, 0.61, 0.69])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "170e2199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: -4.776017714188383\n",
      "Mean Squared Error: 0.08477749999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming y_test and y_pred are your actual and predicted values, respectively\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a48d7b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.7728292626038836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Assuming x and y are your feature and target variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "# Create a linear regression model and fit it to the training data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the R^2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8baae767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "998ed698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a09da",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef3e937b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((862+229)/(862+229+137+179),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723f89c",
   "metadata": {},
   "source": [
    "Recall for 0 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "176786d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(862/(862+137),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823ceb2",
   "metadata": {},
   "source": [
    "# Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "899257fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (1.31.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (13.7.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (15.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (4.9.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (3.1.42)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: importlib-metadata<8,>=1.4 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (4.11.3)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (1.21.5)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (2.27.1)\n",
      "Collecting protobuf<5,>=3.20\n",
      "  Using cached protobuf-4.25.3-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (9.0.1)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (5.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (1.4.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (0.22.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.11.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from importlib-metadata<8,>=1.4->streamlit) (3.7.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (21.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from packaging<24,>=16.8->streamlit) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2021.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages (from tzlocal<6,>=1.1->streamlit) (2024.1)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\pintu kumar sah\\\\anaconda3\\\\Lib\\\\site-packages\\\\google\\\\protobuf\\\\~-ternal\\\\_api_implementation.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pintu kumar sah\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2dbb60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump,load\n",
    "df=pd.read_csv(\"D:\\\\All Subject(6)\\\\Samatrix\\\\archive (8)\\\\Admission_Predict.csv\")\n",
    "\n",
    "df.drop(columns=['Serial No.'],axis=1,inplace=True)\n",
    "df=df.dropna()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "model.add(Dense(7,activation='relu',input_dim=X_train.shape[1]))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.summary()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)\n",
    "from tensorflow import keras\n",
    "from tensorflow import keras \n",
    "from keras.layers import Dense\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(26, input_shape=(26,), activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)\n",
    "y_pred=model.predict(X_test)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "print(LinearRegression_report(y_test,y_pred))\n",
    "\n",
    "st.title(\"Graduate Admission Prediction Visualiztion\")\n",
    "st.write(\"Enter the following features to check if the transaction is Graduate Admission Prediction Visualiztion:\")\n",
    "input_df=st.text_input('Input All features')\n",
    "input_df_lst=input_df.split(',')\n",
    "submit=st.button(\"Submit\")\n",
    "\n",
    "if submit:\n",
    "    features=np.array(input_df_lst,dtype=np.float64)\n",
    "    prediction=model.predict(features.reshape(1,-1))\n",
    "    if prediction[0]==0:\n",
    "        st.write(\" Graduate Admission Prediction\")\n",
    "    else:\n",
    "        st.write(\"Graduate Admission Prediction Visualiztion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3fe1312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -q -O - ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668add83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
